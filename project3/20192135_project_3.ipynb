{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout은 학습 시 노드를 임의의 비율인 dropout rate 만큼 삭제하여 layer에 포함된 weight의 일부만 참여시킨다. 그래서 overfitting을 방지할 수 있다. 아래는 dropout rate를 바꿔줬을 때와 여기에 batch_normalization을 추가해 줬을 때의 accuracy이다.<br><br>\n",
    "dropout = 0.2 accuracy = 87.54% accuracy(+batch normalization) = 88.84% <br>\n",
    "dropout = 0.5 accuracy = 87.00% accuracy(+batch normalization) = 88.29% <br>\n",
    "dropout = 0.8 accuracy = 84.79% accuracy(+batch normalization) = 85.20% <br><br>\n",
    "dropout이 커질수록 accuracy는 점점 작아진다. dropout rate가 클수록 더 적은 데이터 unit이 학습되기 때문에 정확도는 감소한다.<br>\n",
    "batch normalization은 각 batch 별로 평균과 분산을 이용하여 정규화하는 것이기 때문에 overfitting을 막을 수 있다. dropout이 노드를 일부 삭제하여 세분화시켜 앙상블 결합하는 것은 batch normalization에서 활성화 함수에 의해 최적의 분포를 만들어 특징이 잘 나타내도록 하는 것과 효과가 같다. 따라서 dropout은 dropout rate만큼 노드가 제외되기 때문에 학습 자체에서의 계산량이 줄어들지만 batch normalization은 삭제하는 노드가 없고 연산 중간마다 연산 결과를 정규화하고 각 성분의 분포 차로 인해 발생하는 가중치 학습의 불균형을 방지하기 때문에 dropout에 비해 accuracy가 높게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.path.expanduser = lambda path: './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.1965 - accuracy: 0.6194 - val_loss: 0.7336 - val_accuracy: 0.7559\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.7406 - accuracy: 0.7520 - val_loss: 0.6155 - val_accuracy: 0.7908\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6476 - accuracy: 0.7791 - val_loss: 0.5577 - val_accuracy: 0.8116\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5926 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.8217\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5588 - accuracy: 0.8095 - val_loss: 0.5020 - val_accuracy: 0.8296\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5347 - accuracy: 0.8159 - val_loss: 0.4840 - val_accuracy: 0.8355\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5134 - accuracy: 0.8234 - val_loss: 0.4705 - val_accuracy: 0.8391\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.4968 - accuracy: 0.8300 - val_loss: 0.4583 - val_accuracy: 0.8434\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.4863 - accuracy: 0.8311 - val_loss: 0.4557 - val_accuracy: 0.8410\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.4727 - accuracy: 0.8355 - val_loss: 0.4434 - val_accuracy: 0.8465\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4651 - accuracy: 0.8389 - val_loss: 0.4386 - val_accuracy: 0.8475\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4571 - accuracy: 0.8415 - val_loss: 0.4285 - val_accuracy: 0.8503\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4450 - accuracy: 0.8446 - val_loss: 0.4261 - val_accuracy: 0.8511\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4398 - accuracy: 0.8475 - val_loss: 0.4171 - val_accuracy: 0.8557\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4329 - accuracy: 0.8497 - val_loss: 0.4087 - val_accuracy: 0.8576\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4258 - accuracy: 0.8498 - val_loss: 0.4091 - val_accuracy: 0.8583\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4202 - accuracy: 0.8534 - val_loss: 0.4021 - val_accuracy: 0.8596\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4153 - accuracy: 0.8536 - val_loss: 0.3994 - val_accuracy: 0.8618\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4108 - accuracy: 0.8560 - val_loss: 0.3920 - val_accuracy: 0.8625\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4042 - accuracy: 0.8577 - val_loss: 0.3896 - val_accuracy: 0.8637\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3971 - accuracy: 0.8615 - val_loss: 0.3865 - val_accuracy: 0.8641\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3956 - accuracy: 0.8606 - val_loss: 0.3874 - val_accuracy: 0.8637\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3908 - accuracy: 0.8612 - val_loss: 0.3814 - val_accuracy: 0.8653\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3880 - accuracy: 0.8626 - val_loss: 0.3765 - val_accuracy: 0.8689\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3829 - accuracy: 0.8657 - val_loss: 0.3739 - val_accuracy: 0.8691\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3781 - accuracy: 0.8658 - val_loss: 0.3707 - val_accuracy: 0.8697\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3759 - accuracy: 0.8675 - val_loss: 0.3695 - val_accuracy: 0.8694\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3715 - accuracy: 0.8670 - val_loss: 0.3676 - val_accuracy: 0.8706\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3688 - accuracy: 0.8681 - val_loss: 0.3641 - val_accuracy: 0.8717\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3658 - accuracy: 0.8702 - val_loss: 0.3625 - val_accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3619 - accuracy: 0.8716 - val_loss: 0.3604 - val_accuracy: 0.8724\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3592 - accuracy: 0.8720 - val_loss: 0.3594 - val_accuracy: 0.8733\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3562 - accuracy: 0.8730 - val_loss: 0.3571 - val_accuracy: 0.8733\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3545 - accuracy: 0.8737 - val_loss: 0.3563 - val_accuracy: 0.8726\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3499 - accuracy: 0.8754 - val_loss: 0.3546 - val_accuracy: 0.8733\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3496 - accuracy: 0.8748 - val_loss: 0.3500 - val_accuracy: 0.8772\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3454 - accuracy: 0.8764 - val_loss: 0.3497 - val_accuracy: 0.8763\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3445 - accuracy: 0.8760 - val_loss: 0.3472 - val_accuracy: 0.8761\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3421 - accuracy: 0.8778 - val_loss: 0.3476 - val_accuracy: 0.8770\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3412 - accuracy: 0.8773 - val_loss: 0.3452 - val_accuracy: 0.8773\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3377 - accuracy: 0.8794 - val_loss: 0.3479 - val_accuracy: 0.8772\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3339 - accuracy: 0.8808 - val_loss: 0.3428 - val_accuracy: 0.8783\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3321 - accuracy: 0.8813 - val_loss: 0.3417 - val_accuracy: 0.8786\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3305 - accuracy: 0.8813 - val_loss: 0.3399 - val_accuracy: 0.8792\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3273 - accuracy: 0.8826 - val_loss: 0.3425 - val_accuracy: 0.8783\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3273 - accuracy: 0.8821 - val_loss: 0.3362 - val_accuracy: 0.8809\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3240 - accuracy: 0.8835 - val_loss: 0.3370 - val_accuracy: 0.8808\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3220 - accuracy: 0.8854 - val_loss: 0.3364 - val_accuracy: 0.8791\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3197 - accuracy: 0.8859 - val_loss: 0.3335 - val_accuracy: 0.8808\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3179 - accuracy: 0.8857 - val_loss: 0.3363 - val_accuracy: 0.8811\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3163 - accuracy: 0.8876 - val_loss: 0.3303 - val_accuracy: 0.8836\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3123 - accuracy: 0.8879 - val_loss: 0.3294 - val_accuracy: 0.8827\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3125 - accuracy: 0.8879 - val_loss: 0.3330 - val_accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3123 - accuracy: 0.8870 - val_loss: 0.3275 - val_accuracy: 0.8832\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3076 - accuracy: 0.8886 - val_loss: 0.3284 - val_accuracy: 0.8827\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3069 - accuracy: 0.8904 - val_loss: 0.3267 - val_accuracy: 0.8838\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 11s 31ms/step - loss: 0.3065 - accuracy: 0.8912 - val_loss: 0.3242 - val_accuracy: 0.8851\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3031 - accuracy: 0.8910 - val_loss: 0.3236 - val_accuracy: 0.8852\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3019 - accuracy: 0.8920 - val_loss: 0.3236 - val_accuracy: 0.8852\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3001 - accuracy: 0.8928 - val_loss: 0.3225 - val_accuracy: 0.8855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3466 - accuracy: 0.8754\n",
      "0.8754000067710876\n",
      "Accuracy: 87.54%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "# Define Model 0.2 with Batch_Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 14s 34ms/step - loss: 0.7247 - accuracy: 0.7490 - val_loss: 0.5124 - val_accuracy: 0.8213\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.5075 - accuracy: 0.8196 - val_loss: 0.4157 - val_accuracy: 0.8528\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.4556 - accuracy: 0.8376 - val_loss: 0.3867 - val_accuracy: 0.8639\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.4217 - accuracy: 0.8502 - val_loss: 0.3705 - val_accuracy: 0.8672\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.4018 - accuracy: 0.8552 - val_loss: 0.3563 - val_accuracy: 0.8722\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3843 - accuracy: 0.8636 - val_loss: 0.3516 - val_accuracy: 0.8724\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3694 - accuracy: 0.8666 - val_loss: 0.3452 - val_accuracy: 0.8777\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3566 - accuracy: 0.8693 - val_loss: 0.3430 - val_accuracy: 0.8775\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3453 - accuracy: 0.8738 - val_loss: 0.3381 - val_accuracy: 0.8799\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3365 - accuracy: 0.8774 - val_loss: 0.3294 - val_accuracy: 0.8814\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3301 - accuracy: 0.8788 - val_loss: 0.3294 - val_accuracy: 0.8810\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3198 - accuracy: 0.8826 - val_loss: 0.3233 - val_accuracy: 0.8848\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3114 - accuracy: 0.8853 - val_loss: 0.3174 - val_accuracy: 0.8852\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3088 - accuracy: 0.8880 - val_loss: 0.3255 - val_accuracy: 0.8821\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2982 - accuracy: 0.8900 - val_loss: 0.3114 - val_accuracy: 0.8865\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2955 - accuracy: 0.8910 - val_loss: 0.3131 - val_accuracy: 0.8850\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2890 - accuracy: 0.8944 - val_loss: 0.3133 - val_accuracy: 0.8857\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2828 - accuracy: 0.8952 - val_loss: 0.3111 - val_accuracy: 0.8888\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2796 - accuracy: 0.8984 - val_loss: 0.3106 - val_accuracy: 0.8874\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2737 - accuracy: 0.8996 - val_loss: 0.3107 - val_accuracy: 0.8856\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2648 - accuracy: 0.9015 - val_loss: 0.3081 - val_accuracy: 0.8878\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2642 - accuracy: 0.9028 - val_loss: 0.3194 - val_accuracy: 0.8854\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.2602 - accuracy: 0.9042 - val_loss: 0.3046 - val_accuracy: 0.8888\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2533 - accuracy: 0.9065 - val_loss: 0.3057 - val_accuracy: 0.8892\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2509 - accuracy: 0.9066 - val_loss: 0.3032 - val_accuracy: 0.8911\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2457 - accuracy: 0.9094 - val_loss: 0.3030 - val_accuracy: 0.8931\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2426 - accuracy: 0.9120 - val_loss: 0.3029 - val_accuracy: 0.8912\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.2372 - accuracy: 0.9134 - val_loss: 0.3109 - val_accuracy: 0.8872\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2339 - accuracy: 0.9123 - val_loss: 0.3003 - val_accuracy: 0.8927\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2299 - accuracy: 0.9155 - val_loss: 0.3055 - val_accuracy: 0.8895\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2263 - accuracy: 0.9162 - val_loss: 0.3057 - val_accuracy: 0.8892\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2220 - accuracy: 0.9183 - val_loss: 0.3037 - val_accuracy: 0.8908\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2231 - accuracy: 0.9166 - val_loss: 0.3003 - val_accuracy: 0.8933\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2203 - accuracy: 0.9187 - val_loss: 0.3048 - val_accuracy: 0.8909\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2134 - accuracy: 0.9204 - val_loss: 0.3041 - val_accuracy: 0.8893\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2132 - accuracy: 0.9201 - val_loss: 0.3028 - val_accuracy: 0.8929\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2089 - accuracy: 0.9232 - val_loss: 0.3038 - val_accuracy: 0.8915\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2080 - accuracy: 0.9230 - val_loss: 0.3059 - val_accuracy: 0.8918\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2027 - accuracy: 0.9252 - val_loss: 0.3036 - val_accuracy: 0.8938\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.2018 - accuracy: 0.9257 - val_loss: 0.3096 - val_accuracy: 0.8898\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.1983 - accuracy: 0.9262 - val_loss: 0.3025 - val_accuracy: 0.8917\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.1938 - accuracy: 0.9289 - val_loss: 0.3079 - val_accuracy: 0.8898\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1923 - accuracy: 0.9293 - val_loss: 0.3067 - val_accuracy: 0.8906\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1883 - accuracy: 0.9304 - val_loss: 0.3118 - val_accuracy: 0.8898\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1861 - accuracy: 0.9310 - val_loss: 0.3144 - val_accuracy: 0.8916\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1859 - accuracy: 0.9304 - val_loss: 0.3169 - val_accuracy: 0.8912\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1819 - accuracy: 0.9323 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1793 - accuracy: 0.9339 - val_loss: 0.3126 - val_accuracy: 0.8925\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1767 - accuracy: 0.9348 - val_loss: 0.3120 - val_accuracy: 0.8923\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1736 - accuracy: 0.9355 - val_loss: 0.3098 - val_accuracy: 0.8917\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.1732 - accuracy: 0.9361 - val_loss: 0.3106 - val_accuracy: 0.8937\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.1693 - accuracy: 0.9370 - val_loss: 0.3061 - val_accuracy: 0.8939\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.1676 - accuracy: 0.9371 - val_loss: 0.3243 - val_accuracy: 0.8901\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1646 - accuracy: 0.9392 - val_loss: 0.3065 - val_accuracy: 0.8947\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.1628 - accuracy: 0.9395 - val_loss: 0.3257 - val_accuracy: 0.8911\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.1624 - accuracy: 0.9400 - val_loss: 0.3260 - val_accuracy: 0.8901\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 13s 35ms/step - loss: 0.1591 - accuracy: 0.9414 - val_loss: 0.3122 - val_accuracy: 0.8943\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1593 - accuracy: 0.9414 - val_loss: 0.3194 - val_accuracy: 0.8929\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.1537 - accuracy: 0.9433 - val_loss: 0.3200 - val_accuracy: 0.8938\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.1583 - accuracy: 0.9420 - val_loss: 0.3297 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3543 - accuracy: 0.8884\n",
      "0.8884000182151794\n",
      "Accuracy: 88.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "# Define Model 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 1.4219 - accuracy: 0.5107 - val_loss: 0.8141 - val_accuracy: 0.7207\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.9018 - accuracy: 0.6829 - val_loss: 0.6747 - val_accuracy: 0.7587\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.7783 - accuracy: 0.7286 - val_loss: 0.6099 - val_accuracy: 0.7834\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.7092 - accuracy: 0.7525 - val_loss: 0.5697 - val_accuracy: 0.7994\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.6586 - accuracy: 0.7705 - val_loss: 0.5365 - val_accuracy: 0.8119\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6229 - accuracy: 0.7840 - val_loss: 0.5159 - val_accuracy: 0.8211\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5972 - accuracy: 0.7930 - val_loss: 0.4992 - val_accuracy: 0.8241\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5742 - accuracy: 0.7989 - val_loss: 0.4849 - val_accuracy: 0.8301\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5572 - accuracy: 0.8060 - val_loss: 0.4751 - val_accuracy: 0.8292\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5412 - accuracy: 0.8110 - val_loss: 0.4650 - val_accuracy: 0.8341\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5314 - accuracy: 0.8148 - val_loss: 0.4545 - val_accuracy: 0.8393\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5197 - accuracy: 0.8181 - val_loss: 0.4466 - val_accuracy: 0.8394\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5031 - accuracy: 0.8225 - val_loss: 0.4396 - val_accuracy: 0.8427\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4985 - accuracy: 0.8246 - val_loss: 0.4329 - val_accuracy: 0.8453\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4922 - accuracy: 0.8259 - val_loss: 0.4257 - val_accuracy: 0.8472\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4847 - accuracy: 0.8299 - val_loss: 0.4243 - val_accuracy: 0.8492\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.4744 - accuracy: 0.8326 - val_loss: 0.4169 - val_accuracy: 0.8509\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4712 - accuracy: 0.8336 - val_loss: 0.4138 - val_accuracy: 0.8528\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.4657 - accuracy: 0.8352 - val_loss: 0.4091 - val_accuracy: 0.8532\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4589 - accuracy: 0.8383 - val_loss: 0.4060 - val_accuracy: 0.8553\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.4501 - accuracy: 0.8408 - val_loss: 0.4035 - val_accuracy: 0.8543\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4485 - accuracy: 0.8414 - val_loss: 0.3996 - val_accuracy: 0.8565\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.4443 - accuracy: 0.8431 - val_loss: 0.3960 - val_accuracy: 0.8584\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4400 - accuracy: 0.8443 - val_loss: 0.3915 - val_accuracy: 0.8593\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4360 - accuracy: 0.8447 - val_loss: 0.3889 - val_accuracy: 0.8610\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.4300 - accuracy: 0.8467 - val_loss: 0.3866 - val_accuracy: 0.8609\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 0.4295 - accuracy: 0.8472 - val_loss: 0.3845 - val_accuracy: 0.8618\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4217 - accuracy: 0.8505 - val_loss: 0.3817 - val_accuracy: 0.8628\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4208 - accuracy: 0.8497 - val_loss: 0.3782 - val_accuracy: 0.8648\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4167 - accuracy: 0.8529 - val_loss: 0.3776 - val_accuracy: 0.8640\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4154 - accuracy: 0.8514 - val_loss: 0.3759 - val_accuracy: 0.8641\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4104 - accuracy: 0.8549 - val_loss: 0.3738 - val_accuracy: 0.8651\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4059 - accuracy: 0.8559 - val_loss: 0.3709 - val_accuracy: 0.8659\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.4048 - accuracy: 0.8566 - val_loss: 0.3701 - val_accuracy: 0.8666\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.4024 - accuracy: 0.8562 - val_loss: 0.3682 - val_accuracy: 0.8677\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3978 - accuracy: 0.8594 - val_loss: 0.3648 - val_accuracy: 0.8690\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3969 - accuracy: 0.8581 - val_loss: 0.3648 - val_accuracy: 0.8685\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3960 - accuracy: 0.8596 - val_loss: 0.3615 - val_accuracy: 0.8692\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3932 - accuracy: 0.8595 - val_loss: 0.3605 - val_accuracy: 0.8707\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3898 - accuracy: 0.8591 - val_loss: 0.3581 - val_accuracy: 0.8707\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3870 - accuracy: 0.8621 - val_loss: 0.3587 - val_accuracy: 0.8705\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3847 - accuracy: 0.8633 - val_loss: 0.3556 - val_accuracy: 0.8717\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3822 - accuracy: 0.8631 - val_loss: 0.3544 - val_accuracy: 0.8719\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3816 - accuracy: 0.8636 - val_loss: 0.3531 - val_accuracy: 0.8730\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3790 - accuracy: 0.8649 - val_loss: 0.3521 - val_accuracy: 0.8749\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3758 - accuracy: 0.8655 - val_loss: 0.3495 - val_accuracy: 0.8754\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3727 - accuracy: 0.8666 - val_loss: 0.3508 - val_accuracy: 0.8734\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3720 - accuracy: 0.8663 - val_loss: 0.3482 - val_accuracy: 0.8746\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3714 - accuracy: 0.8669 - val_loss: 0.3460 - val_accuracy: 0.8766\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3689 - accuracy: 0.8680 - val_loss: 0.3479 - val_accuracy: 0.8749\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3666 - accuracy: 0.8689 - val_loss: 0.3428 - val_accuracy: 0.8781\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3668 - accuracy: 0.8691 - val_loss: 0.3437 - val_accuracy: 0.8766\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3618 - accuracy: 0.8701 - val_loss: 0.3445 - val_accuracy: 0.8756\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3616 - accuracy: 0.8695 - val_loss: 0.3414 - val_accuracy: 0.8763\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3603 - accuracy: 0.8714 - val_loss: 0.3411 - val_accuracy: 0.8759\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3566 - accuracy: 0.8722 - val_loss: 0.3391 - val_accuracy: 0.8780\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3591 - accuracy: 0.8707 - val_loss: 0.3379 - val_accuracy: 0.8777\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3547 - accuracy: 0.8730 - val_loss: 0.3368 - val_accuracy: 0.8796\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3510 - accuracy: 0.8738 - val_loss: 0.3359 - val_accuracy: 0.8793\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3515 - accuracy: 0.8744 - val_loss: 0.3347 - val_accuracy: 0.8798\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3616 - accuracy: 0.8700\n",
      "0.8700000047683716\n",
      "Accuracy: 87.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "# Define Model 0.5 with Batch_Nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 1.0646 - accuracy: 0.6363 - val_loss: 0.6026 - val_accuracy: 0.7899\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.6901 - accuracy: 0.7556 - val_loss: 0.4848 - val_accuracy: 0.8268\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.6121 - accuracy: 0.7825 - val_loss: 0.4491 - val_accuracy: 0.8388\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5659 - accuracy: 0.7996 - val_loss: 0.4331 - val_accuracy: 0.8446\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5367 - accuracy: 0.8098 - val_loss: 0.4151 - val_accuracy: 0.8519\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5126 - accuracy: 0.8180 - val_loss: 0.4078 - val_accuracy: 0.8537\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.4909 - accuracy: 0.8259 - val_loss: 0.4011 - val_accuracy: 0.8555\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4789 - accuracy: 0.8292 - val_loss: 0.3928 - val_accuracy: 0.8594\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4671 - accuracy: 0.8339 - val_loss: 0.3851 - val_accuracy: 0.8613\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.4549 - accuracy: 0.8360 - val_loss: 0.3807 - val_accuracy: 0.8627\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4493 - accuracy: 0.8387 - val_loss: 0.3740 - val_accuracy: 0.8645\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4387 - accuracy: 0.8435 - val_loss: 0.3680 - val_accuracy: 0.8661\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4280 - accuracy: 0.8452 - val_loss: 0.3640 - val_accuracy: 0.8686\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 16s 42ms/step - loss: 0.4259 - accuracy: 0.8473 - val_loss: 0.3685 - val_accuracy: 0.8662\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.4173 - accuracy: 0.8497 - val_loss: 0.3604 - val_accuracy: 0.8705\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.4146 - accuracy: 0.8507 - val_loss: 0.3617 - val_accuracy: 0.8687\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.4059 - accuracy: 0.8539 - val_loss: 0.3540 - val_accuracy: 0.8727\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4021 - accuracy: 0.8565 - val_loss: 0.3498 - val_accuracy: 0.8757\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3994 - accuracy: 0.8573 - val_loss: 0.3473 - val_accuracy: 0.8750\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3926 - accuracy: 0.8573 - val_loss: 0.3480 - val_accuracy: 0.8737\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3840 - accuracy: 0.8612 - val_loss: 0.3439 - val_accuracy: 0.8771\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3843 - accuracy: 0.8612 - val_loss: 0.3461 - val_accuracy: 0.8770\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3796 - accuracy: 0.8645 - val_loss: 0.3392 - val_accuracy: 0.8769\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3726 - accuracy: 0.8652 - val_loss: 0.3384 - val_accuracy: 0.8783\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3728 - accuracy: 0.8647 - val_loss: 0.3376 - val_accuracy: 0.8777\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3676 - accuracy: 0.8665 - val_loss: 0.3313 - val_accuracy: 0.8803\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.3630 - accuracy: 0.8698 - val_loss: 0.3338 - val_accuracy: 0.8818\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3578 - accuracy: 0.8717 - val_loss: 0.3351 - val_accuracy: 0.8777\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 0.3589 - accuracy: 0.8704 - val_loss: 0.3308 - val_accuracy: 0.8805\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.3568 - accuracy: 0.8721 - val_loss: 0.3327 - val_accuracy: 0.8802\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.3528 - accuracy: 0.8737 - val_loss: 0.3301 - val_accuracy: 0.8782\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.3516 - accuracy: 0.8726 - val_loss: 0.3312 - val_accuracy: 0.8789\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 0.3449 - accuracy: 0.8758 - val_loss: 0.3242 - val_accuracy: 0.8833\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 0.3458 - accuracy: 0.8745 - val_loss: 0.3268 - val_accuracy: 0.8796\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 14s 36ms/step - loss: 0.3401 - accuracy: 0.8759 - val_loss: 0.3254 - val_accuracy: 0.8817\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.3401 - accuracy: 0.8758 - val_loss: 0.3234 - val_accuracy: 0.8846\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3398 - accuracy: 0.8765 - val_loss: 0.3220 - val_accuracy: 0.8829\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3374 - accuracy: 0.8771 - val_loss: 0.3213 - val_accuracy: 0.8831\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3315 - accuracy: 0.8794 - val_loss: 0.3204 - val_accuracy: 0.8847\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.3295 - accuracy: 0.8789 - val_loss: 0.3208 - val_accuracy: 0.8828\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.3285 - accuracy: 0.8799 - val_loss: 0.3168 - val_accuracy: 0.8851\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.3246 - accuracy: 0.8824 - val_loss: 0.3142 - val_accuracy: 0.8851\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 13s 36ms/step - loss: 0.3220 - accuracy: 0.8804 - val_loss: 0.3156 - val_accuracy: 0.8855\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3202 - accuracy: 0.8835 - val_loss: 0.3185 - val_accuracy: 0.8837\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3187 - accuracy: 0.8842 - val_loss: 0.3208 - val_accuracy: 0.8838\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3180 - accuracy: 0.8842 - val_loss: 0.3154 - val_accuracy: 0.8869\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3136 - accuracy: 0.8855 - val_loss: 0.3165 - val_accuracy: 0.8841\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3088 - accuracy: 0.8867 - val_loss: 0.3164 - val_accuracy: 0.8856\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3099 - accuracy: 0.8863 - val_loss: 0.3107 - val_accuracy: 0.8888\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.3107 - accuracy: 0.8869 - val_loss: 0.3156 - val_accuracy: 0.8855\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 14s 37ms/step - loss: 0.3085 - accuracy: 0.8870 - val_loss: 0.3152 - val_accuracy: 0.8863\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3061 - accuracy: 0.8882 - val_loss: 0.3146 - val_accuracy: 0.8867\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3020 - accuracy: 0.8898 - val_loss: 0.3195 - val_accuracy: 0.8850\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.3014 - accuracy: 0.8890 - val_loss: 0.3093 - val_accuracy: 0.8888\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.3002 - accuracy: 0.8900 - val_loss: 0.3143 - val_accuracy: 0.8851\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2972 - accuracy: 0.8914 - val_loss: 0.3084 - val_accuracy: 0.8881\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2981 - accuracy: 0.8910 - val_loss: 0.3090 - val_accuracy: 0.8878\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2940 - accuracy: 0.8915 - val_loss: 0.3091 - val_accuracy: 0.8869\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.2930 - accuracy: 0.8908 - val_loss: 0.3078 - val_accuracy: 0.8896\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.2944 - accuracy: 0.8907 - val_loss: 0.3093 - val_accuracy: 0.8894\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3351 - accuracy: 0.8829\n",
      "0.8828999996185303\n",
      "Accuracy: 88.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "# Define Model 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.8))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 1.9857 - accuracy: 0.2964 - val_loss: 1.2485 - val_accuracy: 0.6533\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.3894 - accuracy: 0.4931 - val_loss: 0.9019 - val_accuracy: 0.6883\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.1606 - accuracy: 0.5704 - val_loss: 0.7841 - val_accuracy: 0.7173\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 1.0342 - accuracy: 0.6184 - val_loss: 0.7244 - val_accuracy: 0.7366\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.9530 - accuracy: 0.6458 - val_loss: 0.6814 - val_accuracy: 0.7552\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.8954 - accuracy: 0.6679 - val_loss: 0.6516 - val_accuracy: 0.7627\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.8532 - accuracy: 0.6861 - val_loss: 0.6264 - val_accuracy: 0.7735\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.8168 - accuracy: 0.6986 - val_loss: 0.6080 - val_accuracy: 0.7802\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.7922 - accuracy: 0.7098 - val_loss: 0.5910 - val_accuracy: 0.7906\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.7607 - accuracy: 0.7207 - val_loss: 0.5747 - val_accuracy: 0.7927\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.7475 - accuracy: 0.7289 - val_loss: 0.5604 - val_accuracy: 0.8005\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.7278 - accuracy: 0.7383 - val_loss: 0.5475 - val_accuracy: 0.8066\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.7097 - accuracy: 0.7455 - val_loss: 0.5350 - val_accuracy: 0.8128\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.6937 - accuracy: 0.7507 - val_loss: 0.5293 - val_accuracy: 0.8161\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6849 - accuracy: 0.7543 - val_loss: 0.5182 - val_accuracy: 0.8217\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6773 - accuracy: 0.7583 - val_loss: 0.5155 - val_accuracy: 0.8213\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.6568 - accuracy: 0.7663 - val_loss: 0.5035 - val_accuracy: 0.8243\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6527 - accuracy: 0.7689 - val_loss: 0.4975 - val_accuracy: 0.8283\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6390 - accuracy: 0.7705 - val_loss: 0.4918 - val_accuracy: 0.8292\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6309 - accuracy: 0.7765 - val_loss: 0.4868 - val_accuracy: 0.8314\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6199 - accuracy: 0.7805 - val_loss: 0.4806 - val_accuracy: 0.8307\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6148 - accuracy: 0.7829 - val_loss: 0.4765 - val_accuracy: 0.8338\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6104 - accuracy: 0.7839 - val_loss: 0.4715 - val_accuracy: 0.8363\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.6062 - accuracy: 0.7879 - val_loss: 0.4687 - val_accuracy: 0.8362\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5973 - accuracy: 0.7932 - val_loss: 0.4632 - val_accuracy: 0.8363\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5944 - accuracy: 0.7902 - val_loss: 0.4592 - val_accuracy: 0.8387\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5873 - accuracy: 0.7942 - val_loss: 0.4563 - val_accuracy: 0.8373\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5789 - accuracy: 0.7969 - val_loss: 0.4546 - val_accuracy: 0.8417\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5790 - accuracy: 0.7981 - val_loss: 0.4512 - val_accuracy: 0.8413\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5722 - accuracy: 0.8001 - val_loss: 0.4469 - val_accuracy: 0.8411\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5689 - accuracy: 0.8004 - val_loss: 0.4425 - val_accuracy: 0.8426\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5619 - accuracy: 0.8058 - val_loss: 0.4417 - val_accuracy: 0.8444\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5606 - accuracy: 0.8042 - val_loss: 0.4378 - val_accuracy: 0.8443\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5555 - accuracy: 0.8071 - val_loss: 0.4365 - val_accuracy: 0.8449\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5476 - accuracy: 0.8083 - val_loss: 0.4346 - val_accuracy: 0.8456\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5452 - accuracy: 0.8094 - val_loss: 0.4314 - val_accuracy: 0.8456\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5453 - accuracy: 0.8082 - val_loss: 0.4304 - val_accuracy: 0.8468\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5401 - accuracy: 0.8090 - val_loss: 0.4298 - val_accuracy: 0.8463\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5384 - accuracy: 0.8128 - val_loss: 0.4294 - val_accuracy: 0.8468\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5367 - accuracy: 0.8112 - val_loss: 0.4268 - val_accuracy: 0.8491\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5333 - accuracy: 0.8151 - val_loss: 0.4237 - val_accuracy: 0.8504\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5321 - accuracy: 0.8156 - val_loss: 0.4222 - val_accuracy: 0.8495\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5276 - accuracy: 0.8174 - val_loss: 0.4199 - val_accuracy: 0.8518\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5248 - accuracy: 0.8157 - val_loss: 0.4197 - val_accuracy: 0.8508\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5207 - accuracy: 0.8186 - val_loss: 0.4180 - val_accuracy: 0.8509\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5148 - accuracy: 0.8204 - val_loss: 0.4167 - val_accuracy: 0.8522\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5145 - accuracy: 0.8191 - val_loss: 0.4126 - val_accuracy: 0.8530\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5116 - accuracy: 0.8202 - val_loss: 0.4131 - val_accuracy: 0.8518\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5141 - accuracy: 0.8216 - val_loss: 0.4103 - val_accuracy: 0.8543\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5074 - accuracy: 0.8259 - val_loss: 0.4115 - val_accuracy: 0.8532\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5075 - accuracy: 0.8236 - val_loss: 0.4101 - val_accuracy: 0.8536\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5088 - accuracy: 0.8222 - val_loss: 0.4086 - val_accuracy: 0.8545\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.5005 - accuracy: 0.8243 - val_loss: 0.4077 - val_accuracy: 0.8537\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4999 - accuracy: 0.8238 - val_loss: 0.4038 - val_accuracy: 0.8553\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.5002 - accuracy: 0.8266 - val_loss: 0.4047 - val_accuracy: 0.8561\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4970 - accuracy: 0.8268 - val_loss: 0.4031 - val_accuracy: 0.8567\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4954 - accuracy: 0.8282 - val_loss: 0.4004 - val_accuracy: 0.8575\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4924 - accuracy: 0.8288 - val_loss: 0.3997 - val_accuracy: 0.8589\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4882 - accuracy: 0.8296 - val_loss: 0.3995 - val_accuracy: 0.8591\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.4878 - accuracy: 0.8294 - val_loss: 0.3971 - val_accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4214 - accuracy: 0.8479\n",
      "0.8478999733924866\n",
      "Accuracy: 84.79%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--\n",
    "# Define Model 0.8 with Batch_Nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 2.0183 - accuracy: 0.3194 - val_loss: 1.0268 - val_accuracy: 0.6763\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.3020 - accuracy: 0.5308 - val_loss: 0.7797 - val_accuracy: 0.7347\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 1.0812 - accuracy: 0.6007 - val_loss: 0.7038 - val_accuracy: 0.7508\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.9761 - accuracy: 0.6415 - val_loss: 0.6669 - val_accuracy: 0.7650\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.8963 - accuracy: 0.6697 - val_loss: 0.6340 - val_accuracy: 0.7774\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.8495 - accuracy: 0.6876 - val_loss: 0.6127 - val_accuracy: 0.7822\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.8104 - accuracy: 0.7042 - val_loss: 0.5925 - val_accuracy: 0.7916\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.7808 - accuracy: 0.7140 - val_loss: 0.5769 - val_accuracy: 0.7994\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.7641 - accuracy: 0.7245 - val_loss: 0.5671 - val_accuracy: 0.8023\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.7326 - accuracy: 0.7326 - val_loss: 0.5526 - val_accuracy: 0.8092\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.7212 - accuracy: 0.7415 - val_loss: 0.5440 - val_accuracy: 0.8152\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.7039 - accuracy: 0.7493 - val_loss: 0.5296 - val_accuracy: 0.8185\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.6900 - accuracy: 0.7541 - val_loss: 0.5144 - val_accuracy: 0.8232\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.6812 - accuracy: 0.7574 - val_loss: 0.5181 - val_accuracy: 0.8178\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.6716 - accuracy: 0.7598 - val_loss: 0.5127 - val_accuracy: 0.8241\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6662 - accuracy: 0.7634 - val_loss: 0.5056 - val_accuracy: 0.8248\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6469 - accuracy: 0.7714 - val_loss: 0.4896 - val_accuracy: 0.8315\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6439 - accuracy: 0.7717 - val_loss: 0.4865 - val_accuracy: 0.8322\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6354 - accuracy: 0.7754 - val_loss: 0.4822 - val_accuracy: 0.8341\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6237 - accuracy: 0.7790 - val_loss: 0.4840 - val_accuracy: 0.8312\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6149 - accuracy: 0.7819 - val_loss: 0.4756 - val_accuracy: 0.8339\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6075 - accuracy: 0.7861 - val_loss: 0.4737 - val_accuracy: 0.8367\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.6095 - accuracy: 0.7866 - val_loss: 0.4671 - val_accuracy: 0.8393\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5987 - accuracy: 0.7892 - val_loss: 0.4655 - val_accuracy: 0.8379\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5952 - accuracy: 0.7911 - val_loss: 0.4645 - val_accuracy: 0.8378\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5937 - accuracy: 0.7916 - val_loss: 0.4563 - val_accuracy: 0.8413\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5824 - accuracy: 0.7956 - val_loss: 0.4526 - val_accuracy: 0.8419\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5781 - accuracy: 0.7968 - val_loss: 0.4514 - val_accuracy: 0.8418\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5787 - accuracy: 0.7971 - val_loss: 0.4479 - val_accuracy: 0.8460\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5714 - accuracy: 0.8000 - val_loss: 0.4455 - val_accuracy: 0.8461\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5680 - accuracy: 0.8013 - val_loss: 0.4419 - val_accuracy: 0.8468\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5636 - accuracy: 0.8036 - val_loss: 0.4435 - val_accuracy: 0.8451\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5599 - accuracy: 0.8054 - val_loss: 0.4360 - val_accuracy: 0.8502\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5595 - accuracy: 0.8031 - val_loss: 0.4377 - val_accuracy: 0.8481\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5531 - accuracy: 0.8053 - val_loss: 0.4334 - val_accuracy: 0.8465\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5478 - accuracy: 0.8093 - val_loss: 0.4300 - val_accuracy: 0.8495\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5466 - accuracy: 0.8098 - val_loss: 0.4308 - val_accuracy: 0.8468\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5416 - accuracy: 0.8095 - val_loss: 0.4273 - val_accuracy: 0.8489\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5412 - accuracy: 0.8110 - val_loss: 0.4276 - val_accuracy: 0.8497\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5398 - accuracy: 0.8113 - val_loss: 0.4255 - val_accuracy: 0.8512\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5387 - accuracy: 0.8131 - val_loss: 0.4225 - val_accuracy: 0.8522\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 13s 33ms/step - loss: 0.5341 - accuracy: 0.8129 - val_loss: 0.4211 - val_accuracy: 0.8512\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5345 - accuracy: 0.8141 - val_loss: 0.4213 - val_accuracy: 0.8536\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5272 - accuracy: 0.8163 - val_loss: 0.4212 - val_accuracy: 0.8535\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5229 - accuracy: 0.8179 - val_loss: 0.4168 - val_accuracy: 0.8515\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5217 - accuracy: 0.8183 - val_loss: 0.4159 - val_accuracy: 0.8531\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5183 - accuracy: 0.8186 - val_loss: 0.4155 - val_accuracy: 0.8514\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5151 - accuracy: 0.8197 - val_loss: 0.4153 - val_accuracy: 0.8530\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5178 - accuracy: 0.8206 - val_loss: 0.4122 - val_accuracy: 0.8551\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5138 - accuracy: 0.8210 - val_loss: 0.4113 - val_accuracy: 0.8518\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5138 - accuracy: 0.8191 - val_loss: 0.4139 - val_accuracy: 0.8550\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5154 - accuracy: 0.8188 - val_loss: 0.4068 - val_accuracy: 0.8562\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5065 - accuracy: 0.8230 - val_loss: 0.4132 - val_accuracy: 0.8522\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5083 - accuracy: 0.8204 - val_loss: 0.4048 - val_accuracy: 0.8572\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5091 - accuracy: 0.8240 - val_loss: 0.4058 - val_accuracy: 0.8572\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.5064 - accuracy: 0.8220 - val_loss: 0.4045 - val_accuracy: 0.8583\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 12s 32ms/step - loss: 0.5050 - accuracy: 0.8239 - val_loss: 0.4053 - val_accuracy: 0.8566\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.5008 - accuracy: 0.8253 - val_loss: 0.4041 - val_accuracy: 0.8565\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4948 - accuracy: 0.8275 - val_loss: 0.4045 - val_accuracy: 0.8567\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.4991 - accuracy: 0.8240 - val_loss: 0.3992 - val_accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4211 - accuracy: 0.8520\n",
      "0.8519999980926514\n",
      "Accuracy: 85.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
